{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "serious-harvey",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "Hopefully you've watched the three videos by [Grant Sanderson](https://twitter.com/3blue1brown) (a.k.a. [3blue1brown](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw)).\n",
    "\n",
    "* [But what is a Neural Network?](https://www.youtube.com/watch?v=aircAruvnKk) (19:13)\n",
    "* [Gradient descent, how neural networks learn](https://www.youtube.com/watch?v=IHZwWFHWa-w) (21:00)\n",
    "* [What is back propagation really doing?](https://www.youtube.com/watch?v=Ilg3gGewQ5U) (13:53)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-plate",
   "metadata": {},
   "source": [
    "## A very brief recap from the homework\n",
    "\n",
    "**Neurons**:\n",
    "\n",
    "* Hold a value\n",
    "* This value is related to the values of neurons on previous layers via:\n",
    "    * **weights**\n",
    "    * **bias**\n",
    "    * **activation function**\n",
    "* Some jargon: weights and biases are called **parameters** of the model (they are estimated from data automatically). The other options about the model are called **hyperparameters**.\n",
    "\n",
    "**Neural network structure**:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/1d/Neural_network_example.png\"  style=\"width:200px;\">\n",
    "\n",
    "* Input layer\n",
    "* one or more hidden layers (this is where the term \"deep\" comes from)\n",
    "* an output layer\n",
    "\n",
    "**Learning**:\n",
    "\n",
    "* Minimizing a **loss function** (or **cost function**) through back propagation\n",
    "  * Loss is often **Mean Squared Error** (**MSE**) between p\n",
    "* An **optimizer** helps find the best possible parameters\n",
    "  * Data is fed to the model with the current weights and biases, and the optimizer instructs how to adjust the weights and biases, and the process is iterated.\n",
    "  * This can be **gradient descent**, which is a slow process.\n",
    "  * The choice of optimizer might mean the difference between a model that is trained in minutes vs days.\n",
    "  * each time the entire set of data is fed to the algorighm, it is called an **epoch**\n",
    "  * some times the adjustment process can be sped up by feeding in the data in smaller **batches** (usually randomly selected) and adjusting the weights more frequently.\n",
    "    * an example of this strategy is **stochastic gradient descent**\n",
    "    * a modern extention to stochastic gradient descent optimizer is the **Adam** optimizer, which is now very commonly used. The math is pretty heavy, but you can read about some of the details here: [Gentle Introduction to the Adam Optimization Algorithm for Deep Learning](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)\n",
    "\n",
    "\n",
    "<img src=\"https://pbs.twimg.com/media/EybMJzOU8AY8g7M?format=png&name=small\"  style=\"width:400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14446947",
   "metadata": {},
   "source": [
    "Now that we have some concepts defined, let's play around with a neural network before touching any code:\n",
    "\n",
    "https://playground.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e494fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data and solutions\n",
    "\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "def download_data(path, branch='main'):\n",
    "    base_url = 'https://raw.githubusercontent.com/ualberta-rcg/python-machine-learning'\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "    if not os.path.exists('data/numbers'):\n",
    "        os.mkdir('data/numbers')\n",
    "    url = '{}/{}/notebooks/{}'.format(base_url, branch, path)\n",
    "    output_file = path\n",
    "    urllib.request.urlretrieve(url, output_file)\n",
    "    print(\"Downloaded \" + path)\n",
    "\n",
    "download_data('data/numbers/cwant_1.png')\n",
    "download_data('data/numbers/cwant_3.png')\n",
    "download_data('data/numbers/cwant_5.png')\n",
    "download_data('data/numbers/cwant_8.png')\n",
    "download_data('data/numbers/cwant_thick_1.png')\n",
    "download_data('data/numbers/cwant_thick_3.png')\n",
    "download_data('data/numbers/cwant_thick_4.png')\n",
    "download_data('data/numbers/cwant_thick_5.png')\n",
    "download_data('data/numbers/cwant_thick_6.png')\n",
    "download_data('data/numbers/cwant_thick_9.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397b5ba5",
   "metadata": {},
   "source": [
    "Like other package we have seen, Keras has a submodule of sample datasets. The **MNIST** dataset of handwritten numbers is included, which we can load as both training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dac4c7f",
   "metadata": {},
   "source": [
    "We can see how many samples are in the **training** features data, and the shape of each sample ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf03f8",
   "metadata": {},
   "source": [
    "Same for the **test** data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07fac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60000\n",
    "num_train = x_train.shape[0]\n",
    "\n",
    "# 10000\n",
    "num_test = x_test.shape[0]\n",
    "\n",
    "# 784\n",
    "num_pixels = x_train.shape[1] * x_train.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f1363c",
   "metadata": {},
   "source": [
    "We can look at an individual sample in the training data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[31] # 32-nd record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d50e61",
   "metadata": {},
   "source": [
    "But it probably makes more sense to convert this data into an image and render it. The `PIL` module makes this easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf364b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "PIL.Image.fromarray(x_train[31])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07d0636",
   "metadata": {},
   "source": [
    "We can then check the label to see that the image corresponds to the number we think it is ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[31]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66807977",
   "metadata": {},
   "source": [
    "We will now transform the feature data to convert each 28 * 28 image to a 784 entry array through the `reshape` method from `numpy.ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fd0435",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train.reshape(num_train, num_pixels)\n",
    "X_test = x_test.reshape(num_test, num_pixels)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0379d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95579fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of 28x28 inputs\n",
    "print(x_train[128][14][13])\n",
    "\n",
    "# Array of 784 inputs, basically shove each row at the end of the previous\n",
    "print(X_train[128][14*28+13])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b95caa0",
   "metadata": {},
   "source": [
    "And we can convert the numbers in the label data to categorial data (basically one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac14f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.utils as ku\n",
    "\n",
    "Y_train = ku.to_categorical(y_train, 10)\n",
    "Y_test = ku.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[26].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-guide",
   "metadata": {},
   "source": [
    "## Sequential model\n",
    "\n",
    "Sequential groups a linear stack of layers. The code below:\n",
    "\n",
    "* Specifies the input layer as having 784 items\n",
    "* Has an intermediate layer with 128 nodes\n",
    "* Has an output layer of 10 nodes\n",
    "\n",
    "Eash layer has a `sigmoid` activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.models as km\n",
    "import keras.layers as kl\n",
    "\n",
    "model = km.Sequential()\n",
    "model.add(kl.Dense(128, input_dim = 784, activation = 'sigmoid', name = 'hidden'))\n",
    "model.add(kl.Dense(10, name = 'output', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-landing",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbabf49",
   "metadata": {},
   "source": [
    "Compiling prepares the model for training.\n",
    "\n",
    "The optimizer chosen here is `sgd` (Stochastic Gradient Descent).\n",
    "\n",
    "The loss/cost function we will use is `mean_squared_error`.\n",
    "\n",
    "The accuracy is reported during training for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              metrics=['accuracy'],\n",
    "              loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-motor",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Gradient Descent is a slow process, so one speed up is to send the data to the algorithms in random batches until all of the data is read (Stochastic Gradient Descent). Each time this happens, it's called an **epoch**.\n",
    "\n",
    "An epoch can be split into **minibatch** (or just **batch**), between which the model's parameters are updated.\n",
    "\n",
    "So the number of epochs you train is how many times the model will see each training sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=25,\n",
    "                    batch_size=100,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00e0eed",
   "metadata": {},
   "source": [
    "We can now check out the accuracy of our model on our unseen test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9326f09b",
   "metadata": {},
   "source": [
    "What's up with that `history` variable that's output from training? It provides some information about the loss and accuracy for each epoch.\n",
    "\n",
    "We can use this to plot the loss and accuracy over the epochs for this training session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a680e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'accuracy']].plot();\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy/Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520cc55d",
   "metadata": {},
   "source": [
    "**Now run the training and evaluation cells again.** (Training continues where we left off, and we can continue training the same model.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedabae9",
   "metadata": {},
   "source": [
    "## Exercise: the ultimate test\n",
    "\n",
    "Now the ultimate test: can this model correctly detect **your** hand-drawn numbers?\n",
    "\n",
    "You might want to try drawing your own number here:\n",
    "\n",
    "https://drawisland.com/?w=200&h=200\n",
    "\n",
    "Rules:\n",
    "* Draw a digit with a black pen on a white background (default)\n",
    "* Perhaps bump up the pen size\n",
    "* Click the **Save** button to save a `png` file to your computer (hint: put the digit you drew as part of the filename).\n",
    "* Put the image (or upload to Colab) in the subdirectory `data/numbers` of your current workbook directory. There should be some `png` files of numbers I drew already in there.\n",
    "\n",
    "To figure out the current notebook directory, uncomment one of the lines with the exclamation mark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e18adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux/Mac/Colab\n",
    "# !pwd\n",
    "\n",
    "# Windows\n",
    "# !dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e7810c",
   "metadata": {},
   "source": [
    "We can write a function that loads/displays/transforms/predicts an image file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461bb96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import PIL.ImageOps\n",
    "import numpy as np\n",
    "\n",
    "def image_predict(model, filename):\n",
    "    # Load and resize to 8x8\n",
    "    image = PIL.Image.open(filename).resize( (28,28) ).convert( 'L' )\n",
    "    # Switch black and white\n",
    "    image = PIL.ImageOps.invert(image)\n",
    "    # Display\n",
    "    print(\"Filename: {}\".format(filename))\n",
    "    print(\"Image:\")\n",
    "    display(image)\n",
    "    # Convert to numpy array and reshape as 784 length vector\n",
    "    image_array = np.array(image)[:,:].reshape(784)\n",
    "    # Predict!\n",
    "    prediction = model.predict(np.array([image_array])).argmax()\n",
    "    print(\"Prediction: {}\\n\".format(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80ee3d",
   "metadata": {},
   "source": [
    "We can now test it out on your file (replace `cwant_8.png` with your filename):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f23ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ('data/numbers/*.png'):\n",
    "image_predict(model, 'data/numbers/cwant_8.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faabc648",
   "metadata": {},
   "source": [
    "Did the model predict the correct number?\n",
    "\n",
    "We use the `glob` module to predict all of the numbers in the `data/numbers` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099bb5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for filename in glob.glob('data/numbers/*.png'):\n",
    "    image_predict(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27377279",
   "metadata": {},
   "source": [
    "How did you the model do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b25fb9",
   "metadata": {},
   "source": [
    "## How about adding another layer?\n",
    "\n",
    "We now have more than three layers (including input and output), so our network is considered to be **deep** (and we are doing **deep learning**). In general, the deeper the network, the more complex learning it can do (at the cost of having to optimize many more parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff31207",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = km.Sequential()\n",
    "model.add(kl.Dense(128, input_dim = 784, activation = 'sigmoid', name = 'hidden'))\n",
    "model.add(kl.Dense(128, activation = 'sigmoid', name = 'hidden2'))\n",
    "model.add(kl.Dense(10, name = 'output', activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              metrics=['accuracy'],\n",
    "              loss=\"mean_squared_error\")\n",
    "\n",
    "# We will take the default batch size (32)\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=25,\n",
    "                    verbose=1)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7115f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for filename in glob.glob('data/numbers/*.png'):\n",
    "    image_predict(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0ae7a4",
   "metadata": {},
   "source": [
    "This time the descent of the loss is slower, and the accuracy is less impressive. We would need a lot more epochs to train this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8794c03f",
   "metadata": {},
   "source": [
    "## How about just a wider layer?\n",
    "\n",
    "Another way to have a network learn more complex patterns is with wider layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = km.Sequential()\n",
    "model.add(kl.Dense(1024, input_dim = 784, activation = 'sigmoid', name = 'hidden'))\n",
    "model.add(kl.Dense(10, name = 'output', activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              metrics=['accuracy'],\n",
    "              loss=\"mean_squared_error\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=25,\n",
    "                    verbose=1)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d7350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for filename in glob.glob('data/numbers/*.png'):\n",
    "    image_predict(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd85a1",
   "metadata": {},
   "source": [
    "## How about a different activation function?\n",
    "\n",
    "Our current activation is a sigmoid:\n",
    "\n",
    "There is another very popular activation function called \"The Rectified Linear Unit\" (ReLu) that is used in machine learning:\n",
    "\n",
    "Lets set up our model again to use ReLu for one of the hidden layers ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef04f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = km.Sequential()\n",
    "model.add(kl.Dense(128, input_dim = 784, activation = 'sigmoid', name = 'hidden'))\n",
    "model.add(kl.Dense(128, activation = 'relu', name = 'hidden2'))\n",
    "model.add(kl.Dense(10, name = 'output', activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              metrics=['accuracy'],\n",
    "              loss=\"mean_squared_error\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=25,\n",
    "                    batch_size=100,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4336c23",
   "metadata": {},
   "source": [
    "The ReLu helps the training go quicker ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141285bf",
   "metadata": {},
   "source": [
    "## Different optimizer (adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ba89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.Dense(128, input_dim = 784, activation = 'sigmoid', name = 'hidden'))\n",
    "model.add(kl.Dense(128, activation = 'relu', name = 'hidden2'))\n",
    "model.add(kl.Dense(10, name = 'output', activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              metrics=['accuracy'],\n",
    "              loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54fda4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=25,\n",
    "#                    batch_size=100,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ff334",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'accuracy']].plot();\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy/Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ee6631",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in glob.glob('data/numbers/*.png'):\n",
    "    image_predict(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae1fc4a",
   "metadata": {},
   "source": [
    "### A third ReLu layer ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e55fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.Dense(128, input_dim = 784, activation = 'sigmoid', name = 'hidden'))\n",
    "model.add(kl.Dense(128, activation = 'relu', name = 'hidden2'))\n",
    "model.add(kl.Dense(128, activation = 'relu', name = 'hidden3'))\n",
    "model.add(kl.Dense(10, name = 'output', activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              metrics=['accuracy'],\n",
    "              loss=\"mean_squared_error\")\n",
    "\n",
    "%time history = model.fit(X_train, Y_train, epochs=25)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec56270",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in glob.glob('data/numbers/*.png'):\n",
    "    image_predict(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41d4a20",
   "metadata": {},
   "source": [
    "# Stopping early ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a98bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=3, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model = km.Sequential()\n",
    "model.add(kl.Dense(128, input_dim = 784, activation = 'sigmoid', name = 'hidden'))\n",
    "model.add(kl.Dense(128, activation = 'relu', name = 'hidden2'))\n",
    "model.add(kl.Dense(128, activation = 'relu', name = 'hidden3'))\n",
    "model.add(kl.Dense(10, name = 'output', activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              metrics=['accuracy'],\n",
    "              loss=\"mean_squared_error\")\n",
    "\n",
    "%time history = model.fit(X_train, Y_train, epochs=25, callbacks=[early_stopping])\n",
    "\n",
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90721020",
   "metadata": {},
   "source": [
    "## Dropping out ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c0ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = km.Sequential()\n",
    "model.add(kl.Dense(128, input_dim = 784, activation = 'sigmoid', name = 'hidden'))\n",
    "model.add(kl.Dropout(0.2))\n",
    "model.add(kl.Dense(128, activation = 'relu', name = 'hidden2'))\n",
    "model.add(kl.Dropout(0.2))\n",
    "model.add(kl.Dense(128, activation = 'relu', name = 'hidden3'))\n",
    "model.add(kl.Dropout(0.2))\n",
    "model.add(kl.Dense(10, name = 'output', activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              metrics=['accuracy'],\n",
    "              loss=\"mean_squared_error\")\n",
    "\n",
    "%time history = model.fit(X_train, Y_train, epochs=25)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb3182",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in glob.glob('data/numbers/*.png'):\n",
    "    image_predict(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff2b0ee",
   "metadata": {},
   "source": [
    "# JUNKYARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea20edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1510b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(pd.DataFrame(fit.history)[['accuracy', 'loss']])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e5eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f05ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8897cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model.make_predict_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    batch_size=1000,\n",
    "    epochs=1,\n",
    "    # callbacks=[early_stopping], # put your callbacks in a list\n",
    "    verbose=1,  # turn off training log\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc4da82",
   "metadata": {},
   "source": [
    "Activation functions\n",
    "Optimizers\n",
    "\n",
    "https://playground.tensorflow.org/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-bennett",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "What do you call it when your model works great on the training data, but doesn't work so well on unseen data?\n",
    "\n",
    "\n",
    "## TODO: Good section on overfitting and underfitting:\n",
    "\n",
    "https://www.kaggle.com/ryanholbrook/overfitting-and-underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-illness",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "Regularization is a method we can use to tackle overfitting.\n",
    "\n",
    "To quote the SciNet neural networks workshop:\n",
    "\n",
    "\"Regularization is an ad hoc technique by which parameters in a model are penalized to prevent\n",
    "individual parameters from becoming excessively important to the fit.\"\n",
    "\n",
    "This technique involves a modification to the cost function our training uses to treat (the extent to which high parameters are penalized is controlled by a parameter lambda ($\\lambda$). (Note that we can't call the parameter `lambda` below, because `lambda` is a reserved keywork in python, so we call in `lam`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.models as km\n",
    "import keras.layers as kl\n",
    "import keras.regularizers as kr\n",
    "\n",
    "def get_regularized_model(numnodes, lam=0.0):\n",
    "  model = km.Sequential()\n",
    "  model.add(kl.Dense(numnodes, input_dim = 784, activation = 'sigmoid', name = 'hidden', kernel_regularizer = kr.l2(lam)))\n",
    "  model.add(kl.Dense(10, name = 'output', activation = 'sigmoid',kernel_regularizer = kr.l2(lam)))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = get_regularized_model(30, lam = 0.001)\n",
    "\n",
    "model2.compile(optimizer = 'sgd', metrics = ['accuracy'], loss = \"mean_squared_error\")\n",
    "\n",
    "%time fit2 = model2.fit(x_train2, y_train2, epochs = 1000, batch_size = 5, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(x_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_more(numnodes):\n",
    "  model = km.Sequential()\n",
    "  model.add(kl.Dense(numnodes, input_dim = 784, activation = 'sigmoid', name = 'hidden'))\n",
    "  model.add(kl.Dense(numnodes, input_dim = numnodes, activation = 'sigmoid', name = 'hidden2'))\n",
    "  model.add(kl.Dense(10, name = 'output', activation = 'sigmoid'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "NUM_TRAINING = 4000 # 60000 max\n",
    "NUM_TESTING = 1000 # 10000 max\n",
    "\n",
    "NUM_NODES = 30\n",
    "NUM_HIDDEN_LAYERS = 1\n",
    "\n",
    "BATCH_SIZE=1000\n",
    "EPOCHS=150\n",
    "\n",
    "LAM=0.001\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_data(num_training=NUM_TRAINING,\n",
    "                                                num_testing=NUM_TESTING)\n",
    "#model = get_model(num_nodes=NUM_NODES,\n",
    "#                  num_hidden_layers=NUM_HIDDEN_LAYERS,\n",
    "#                  lam=LAM)\n",
    "\n",
    "train_model(model,\n",
    "            x_train,\n",
    "            y_train,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            epochs=EPOCHS)\n",
    "\n",
    "evaluate_model(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for filename in glob.glob('data/numbers/*.png'):\n",
    "    model_predict(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "y_values = [v.argmax() for v in y_train]\n",
    "pandas.Series(y_values).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2993fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86903e6",
   "metadata": {},
   "source": [
    "## Example MNIST\n",
    "\n",
    "https://www.kaggle.com/hassanamin/tensorflow-mnist-gpu-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed1d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab9ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9836fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = ku.to_categorical(y_train[:], 10)\n",
    "#y_test = ku.to_categorical(y_test[:], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3715a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e697cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "#  keras.layers.Flatten(input_shape=(28, 28)),\n",
    "model.add(kl.Dense(128, input_dim = 784, activation='relu'))\n",
    "model.add(kl.Dense(128, activation='relu'))\n",
    "model.add(kl.Dense(128, activation='relu'))\n",
    "#odel.add(kl.Dropout(0.2))\n",
    "model.add(kl.Dense(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ab46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "#model.compile(optimizer='adam',\n",
    "#              #loss=loss_fn,\n",
    "#              metrics=['accuracy'])\n",
    "model.compile(optimizer = 'sgd', metrics = ['accuracy'], loss = \"mean_squared_error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec92505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50611194",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9446cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model, filename):\n",
    "    image = Image.open(filename).resize( (28,28) ).convert( 'L' )\n",
    "    image = ImageOps.invert(image)\n",
    "    print(\"Filename: {}\".format(filename))\n",
    "    print(\"Image:\")\n",
    "    display(image)\n",
    "    image_array = np.array(image)\n",
    "    prediction = model.predict(np.array([image_array])).argmax()\n",
    "    print(\"Prediction: {}\\n\".format(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7f476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for filename in glob.glob('data/numbers/*.png'):\n",
    "    model_predict(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "  keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#  keras.layers.Dense(128, activation='relu'),\n",
    "#  keras.layers.Dense(128, activation='relu'),\n",
    "#  keras.layers.Dense(128, activation='relu'),\n",
    "  keras.layers.Dropout(0.2),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "%time model.fit(x_train, y_train, epochs=10)\n",
    "model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "for filename in glob.glob('data/numbers/*.png'):\n",
    "    image_predict(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee23a211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "  keras.layers.InputLayer(784),\n",
    "  keras.layers.Dense(128, activation='relu'),\n",
    "#  keras.layers.Dense(128, activation='relu'),\n",
    "#  keras.layers.Dense(128, activation='relu'),\n",
    "  keras.layers.Dropout(0.2),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "%time model.fit(X_train, Y_train, epochs=10)\n",
    "model.evaluate(X_test,  Y_test, verbose=2)\n",
    "\n",
    "for filename in glob.glob('data/numbers/*.png'):\n",
    "    image_predict(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428a4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "PIL.Image.fromarray(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7873a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(filename):\n",
    "    image = Image.open(filename).resize( (28,28) ).convert( 'L' )\n",
    "    image = ImageOps.invert(image)\n",
    "    print(\"Image:\")\n",
    "    display(image)\n",
    "    image_array = np.array(image)[:,:]\n",
    "    prediction = model.predict(np.array([image_array])).argmax()\n",
    "    print(\"Prediction: {}\".format(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb27f8a",
   "metadata": {},
   "source": [
    "## Saving models\n",
    "\n",
    "So you've spent a lot of time training a model... now what? If we want to use the model in the future, do we have to retrain your model again?\n",
    "\n",
    "No. What you probably want to do is save your trained model for use elsewhere.\n",
    "\n",
    "A potential workflow:\n",
    "\n",
    "* Train your model on an HPC cluster\n",
    "* Dump and download your model\n",
    "* Use your model to predict elsewhere\n",
    "\n",
    "Converting your in-memory data into a form that can be written to disk (and read again later) is called **serialization**. For generic use cases, Python comes with a popular package for serializing variables called **`pickle`**.\n",
    "\n",
    "The Keras documentation has a section on how to serialize and save your trained models, using some methods that are defined for the model objects.\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/save_and_serialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac70e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899505f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71847652",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d449d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for filename in glob.glob('data/numbers/*.png'):\n",
    "    model_predict(loaded_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0455825",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600cc983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "help(tf.saved_model.SaveOptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769af19c",
   "metadata": {},
   "source": [
    "I will be adapting a lot of this material from:\n",
    "\n",
    "* The SciNet workshop on neural networks:\n",
    "  \n",
    "  https://support.scinet.utoronto.ca/education/go.php/451/index.php/ib/1//p_course/451\n",
    "  \n",
    "  This course goes a lot deeper into the mathematics of neural networks.\n",
    "* The Kaggle course on neural networks\n",
    "  \n",
    "  https://www.kaggle.com/learn/intro-to-deep-learning\n",
    "  \n",
    "  A nice interactive approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee27586",
   "metadata": {},
   "source": [
    "## Further exploration\n",
    "\n",
    "* Convolutional Neural Networks\n",
    "  * https://www.cs.ryerson.ca/~aharley/vis/conv/flat.html\n",
    "* Transfer learning\n",
    "  * Using pre-trained neural networks as an initial base for more specific training\n",
    "* Free book!\n",
    "  * http://neuralnetworksanddeeplearning.com/\n",
    "* Kaggle courses\n",
    "  * https://www.kaggle.com/learn\n",
    "  * Do tutorials\n",
    "  * Each tutorial has a challenge notebooks to complete to get credit\n",
    "  * At the end of the course you get a certificate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
