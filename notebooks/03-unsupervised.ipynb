{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The problem**: we have some data, and we aren't given a label that neatly categorizes it. But we want to separate the data in some meaningful way (in clusters, using some measure of nearness).\n",
    "\n",
    "**We need to supply how many clusters we want the algorithm to find ahead of time.**\n",
    "\n",
    "We don't know what the clusters represent, just that we are hoping that there will be a division in the data that will help us understand it.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example, we'll explore unsupervised clustering with an algorithm called KMeans.\n",
    "\n",
    "First, lets create a function to create a mock dataset for us.\n",
    "\n",
    "The function will sample one thousand points in the x-y plane (`blobs`) from 3 different probability distributions using the Scikit-learn function `make_blobs`. We will keep track of which distribution each point is sampled from (`cluster_labels`).\n",
    "\n",
    "These will be returned from our function and stored in the variables `xy_points` and `labels` (**note: the KMeans algorithm won't know about the label here, but we can use it in this contrived example to examine the output**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "numpy.random.seed(1337)\n",
    "\n",
    "centers = [[-10, -10], [-10, 13], [8, -1]]\n",
    "\n",
    "def get_points_and_labels(**kwargs):\n",
    "    blobs, cluster_labels = make_blobs(n_samples=1000, n_features=3,\n",
    "                                       centers=centers, cluster_std=5.0)\n",
    "    return blobs, cluster_labels\n",
    "\n",
    "xy_points, labels = get_points_and_labels(initialize_seed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets make a function that will visualize our x-y points, optionally coloring the points if the labels are also included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def plot_clusters(title, xy_points, labels=None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    xy_points_df = pd.DataFrame(xy_points, columns=['x', 'y'])\n",
    "\n",
    "    if labels is None:\n",
    "        plt.scatter(xy_points_df.x, xy_points_df.y, c=\"grey\")\n",
    "    else:\n",
    "        xy_points_df['labels'] = pd.Series(labels)\n",
    "        colours = list(mcolors.TABLEAU_COLORS.keys())\n",
    "        clusters = range(len(set(labels)))\n",
    "        for cluster_id in clusters:\n",
    "            cluster_data = \\\n",
    "                xy_points_df.loc[xy_points_df[\"labels\"] == cluster_id,\n",
    "                                 [\"x\", \"y\"]]\n",
    "            plt.scatter(cluster_data.x, cluster_data.y,\n",
    "                        c=colours[cluster_id-1])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our x-y points both with and without the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('First 10 xy_points: \\n',xy_points[:10])\n",
    "plot_clusters('Unlabeled clusters', xy_points)\n",
    "print('First 10 labels: \\n', labels[:10])\n",
    "plot_clusters('Labeled clusters', xy_points, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans\n",
    "\n",
    "From [Wikipedia](https://en.wikipedia.org/wiki/K-means_clustering) ...\n",
    "\n",
    "---\n",
    "\n",
    "1. k initial randomly chosen \"means\" (or \"seeds\", in this case k=3) are randomly generated within the data domain (shown in color).\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/K_Means_Example_Step_1.svg/200px-K_Means_Example_Step_1.svg.png)\n",
    "\n",
    "---\n",
    "\n",
    "2. k clusters are created by associating every observation with the nearest mean.\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/K_Means_Example_Step_2.svg/200px-K_Means_Example_Step_2.svg.png)\n",
    "\n",
    "---\n",
    "\n",
    "3. The centroid of each of the k clusters becomes the new mean.\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/K_Means_Example_Step_3.svg/200px-K_Means_Example_Step_3.svg.png)\n",
    "\n",
    "---\n",
    "\n",
    "4. Steps 2 and 3 are repeated until convergence has been reached (not quaranteed)\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/K_Means_Example_Step_4.svg/200px-K_Means_Example_Step_4.svg.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In Scikit-learn, KMeans is provided by the [`sklearn.cluster.KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) class.\n",
    "\n",
    "Notice that we specify the number of clusters we want the algorithm to find `n_clusters`.\n",
    "The setting `n_init=1000` means that we will try 1000 times with different initial means, then choose the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=3, n_init=1000)\n",
    "model.fit(xy_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nActual cluster means')\n",
    "for x_y in centers:\n",
    "    print('%f,%f' % (x_y[0], x_y[1]))\n",
    "    \n",
    "print('\\nPredicted cluster means')\n",
    "for x_y in model.cluster_centers_:\n",
    "    print('%f,%f' % (x_y[0], x_y[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans_labels = model.predict(xy_points)\n",
    "\n",
    "print('First 10 actual labels: ', labels[:10])\n",
    "print('First 10 computed labels: ', kmeans_labels[:10])\n",
    "\n",
    "plot_clusters('Re-plot of original clusters', xy_points, labels)\n",
    "plot_clusters('Calculated clusters', xy_points, kmeans_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huh?\n",
    "\n",
    "Notice that most of the predicted labels are actually wrong!\n",
    "\n",
    "KMeans finds clusters, but it has no way of knowing what the actual labels mean. It just detects clusters.\n",
    "\n",
    "You will notice in the above plot that the shape of the clusters are pretty close, but the colors of the individual clusters might be wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Trying our model out on some new data\n",
    "\n",
    "We can sample a new dataset from the same probability distribution and use our trained model to predict clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_points2, labels2 = get_points_and_labels()\n",
    "kmeans_labels2 = model.predict(xy_points2)\n",
    "\n",
    "plot_clusters('New clusters', xy_points2, labels2)\n",
    "plot_clusters('New predicted clusters', xy_points2, kmeans_labels2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That was all nice and easy, but ...\n",
    "\n",
    "What if our data looks like this instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "features, labels = make_moons(n_samples=1000, noise=0.1)\n",
    "\n",
    "plot_clusters('Uh oh ...', features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or how about this one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "features, labels = make_circles(n_samples=1000, noise=0.1, factor=0.5)\n",
    "\n",
    "plot_clusters('Uh oh 2.0...', features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In these cases, KMeans may not be the best algorithm to try for clustering.\n",
    "\n",
    "You can see a number of different clustering algorithms, and instances where some algorithms might work better than others:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/clustering.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Try one of the algorithms on the Scikit-learn webpage to create a pipeline to cluster one of the above datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Consider the following dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris['data'], columns= iris['feature_names'])\n",
    "\n",
    "labels = np.array(iris['target'])\n",
    "\n",
    "# Note: label == 0 ==> 'setosa'\n",
    "#       label == 1 ==> 'versicolor'\n",
    "#       label == 2 ==> 'virginica'\n",
    "\n",
    "print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four features in the `iris_df` dataframe -- cluster them!.\n",
    "Plot any two of the features both with the original labels, and with the cluster colors (try different combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ...\n",
    "\n",
    "# Hint, to get two features for a plot ...\n",
    "# xy_points_iris = iris_df[['some feature', 'some other feature']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "The next section is on neural networks. It's good to understand some of the theory behind neural networks, before diving in. I am not an expert at this, and I certainly don't think I can do a better job explaining some of the concepts behind neural networks than [Grant Sanderson](https://twitter.com/3blue1brown) (a.k.a. [3blue1brown](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw)).\n",
    "\n",
    "He has three short introductory videos on how neural networks work, and how they are trained.\n",
    "\n",
    "* [But what is a Neural Network?](https://www.youtube.com/watch?v=aircAruvnKk) (19:13)\n",
    "* [Gradient descent, how neural networks learn](https://www.youtube.com/watch?v=IHZwWFHWa-w) (21:00)\n",
    "* [What is back propagation really doing?](https://www.youtube.com/watch?v=Ilg3gGewQ5U) (13:53)\n",
    "\n",
    "(He has a fourth video in the series, feel free to watch it if you want to get deep into the calculus involved -- not necessary for what we are doing.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "And on to the next section is on [neural networks](04-neural-networks.ipynb)..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
